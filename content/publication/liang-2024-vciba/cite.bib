@article{Liang_2024_VCIBA,
 abstract = {Flipover, an enhanced dropout technique, is introduced to improve the robustness of artificial neural networks. In contrast to dropout, which involves randomly removing certain neurons and their connections, flipover randomly selects neurons and reverts their outputs using a negative multiplier during training. This approach offers stronger regularization than conventional dropout, refining model performance by (1) mitigating overfitting, matching or even exceeding the efficacy of dropout; (2) amplifying robustness to noise; and (3) enhancing resilience against adversarial attacks. Extensive experiments across various neural networks affirm the effectiveness of flipover in deep learning.},
 author = {Yuxuan Liang and Chuang Niu and Pingkun Yan and Ge Wang},
 doi = {10.1186/s42492-024-00153-y},
 journal = {Visual Computing for Industry, Biomedicine, and Art},
 month = {February},
 number = {4},
 pages = {074001},
 title = {Flipover outperforms dropout in deep learning},
 url = {https://vciba.springeropen.com/articles/10.1186/s42492-024-00153-y},
 volume = {7},
 year = {2024}
}
