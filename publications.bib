@article{Liang_2022_pmb,
    doi = {10.1088/1361-6560/ac5b21},
    url = {https://dx.doi.org/10.1088/1361-6560/ac5b21},
    year = {2022},
    month = {mar},
    publisher = {IOP Publishing},
    volume = {67},
    number = {7},
    pages = {074001},
    author = {Yuxuan Liang and Chuang Niu and Chen Wei and Shenghan Ren and Wenxiang Cong and Ge Wang},
    title = {Phase function estimation from a diffuse optical image via deep learning},
    journal = {Physics in Medicine & Biology},
    abstract = {Objective. The phase function is a key element of a light propagation model for Monte Carlo (MC) simulation, which is usually fitted with an analytic function with associated parameters. In recent years, machine learning methods were reported to estimate the parameters of the phase function of a particular form such as the Henyey–Greenstein phase function but, to our knowledge, no studies have been performed to determine the form of the phase function. Approach. Here we design a convolutional neural network (CNN) to estimate the phase function from a diffuse optical image without any explicit assumption on the form of the phase function. Specifically, we use a Gaussian mixture model (GMM) as an example to represent the phase function generally and learn the model parameters accurately. The GMM is selected because it provides the analytic expression of phase function to facilitate deflection angle sampling in MC simulation, and does not significantly increase the number of free parameters. Main Results. Our proposed method is validated on MC-simulated reflectance images of typical biological tissues using the Henyey–Greenstein phase function with different anisotropy factors. The mean squared error of the phase function is 0.01 and the relative error of the anisotropy factor is 3.28%. Significance. We propose the first data-driven CNN-based inverse MC model to estimate the form of scattering phase function. The effects of field of view and spatial resolution are analyzed and the findings provide guidelines for optimizing the experimental protocol in practical applications.}
}

@article{Liang_2024_VCIBA,
    doi = {10.1186/s42492-024-00153-y},
    url = {https://vciba.springeropen.com/articles/10.1186/s42492-024-00153-y},
    year = {2024},
    month = {February},
    volume = {7},
    number = {4},
    pages = {074001},
    author = {Yuxuan Liang and Chuang Niu and Pingkun Yan and Ge Wang},
    title = {Flipover outperforms dropout in deep learning},
    journal = {Visual Computing for Industry, Biomedicine, and Art},
    abstract = {Flipover, an enhanced dropout technique, is introduced to improve the robustness of artificial neural networks. In contrast to dropout, which involves randomly removing certain neurons and their connections, flipover randomly selects neurons and reverts their outputs using a negative multiplier during training. This approach offers stronger regularization than conventional dropout, refining model performance by (1) mitigating overfitting, matching or even exceeding the efficacy of dropout; (2) amplifying robustness to noise; and (3) enhancing resilience against adversarial attacks. Extensive experiments across various neural networks affirm the effectiveness of flipover in deep learning.}
}

@article{Liang_2024_Meta,
    title = {Unbiasing fairness evaluation of radiology AI model},
    journal = {Meta-Radiology},
    volume = {2},
    number = {3},
    pages = {100084},
    year = {2024},
    issn = {2950-1628},
    doi = {https://doi.org/10.1016/j.metrad.2024.100084},
    url = {https://www.sciencedirect.com/science/article/pii/S2950162824000377},
    author = {Yuxuan Liang and Hanqing Chao and Jiajin Zhang and Ge Wang and Pingkun Yan},
    keywords = {Fairness, Deep learning, Evaluation metrics, Data uncertainty, Medical imaging},
    abstract = {Fairness of artificial intelligence and machine learning models, often caused by imbalanced datasets, has long been a concern. While many efforts aim to minimize model bias, this study suggests that traditional fairness evaluation methods may be biased, highlighting the need for a proper evaluation scheme with multiple evaluation metrics due to varying results under different criteria. Moreover, the limited data size of minority groups introduces significant data uncertainty, which can undermine the judgement of fairness. This paper introduces an innovative evaluation approach that estimates data uncertainty in minority groups through bootstrapping from majority groups for a more objective statistical assessment. Extensive experiments reveal that traditional evaluation methods might have drawn inaccurate conclusions about model fairness. The proposed method delivers an unbiased fairness assessment by adeptly addressing the inherent complications of model evaluation on imbalanced datasets. The results show that such comprehensive evaluation can provide more confidence when adopting those models.}
}