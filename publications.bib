@article{Liang_2022_pmb,
    doi = {10.1088/1361-6560/ac5b21},
    url = {https://dx.doi.org/10.1088/1361-6560/ac5b21},
    year = {2022},
    month = {mar},
    publisher = {IOP Publishing},
    volume = {67},
    number = {7},
    pages = {074001},
    author = {Yuxuan Liang and Chuang Niu and Chen Wei and Shenghan Ren and Wenxiang Cong and Ge Wang},
    title = {Phase function estimation from a diffuse optical image via deep learning},
    journal = {Physics in Medicine & Biology},
    abstract = {Objective. The phase function is a key element of a light propagation model for Monte Carlo (MC) simulation, which is usually fitted with an analytic function with associated parameters. In recent years, machine learning methods were reported to estimate the parameters of the phase function of a particular form such as the Henyey–Greenstein phase function but, to our knowledge, no studies have been performed to determine the form of the phase function. Approach. Here we design a convolutional neural network (CNN) to estimate the phase function from a diffuse optical image without any explicit assumption on the form of the phase function. Specifically, we use a Gaussian mixture model (GMM) as an example to represent the phase function generally and learn the model parameters accurately. The GMM is selected because it provides the analytic expression of phase function to facilitate deflection angle sampling in MC simulation, and does not significantly increase the number of free parameters. Main Results. Our proposed method is validated on MC-simulated reflectance images of typical biological tissues using the Henyey–Greenstein phase function with different anisotropy factors. The mean squared error of the phase function is 0.01 and the relative error of the anisotropy factor is 3.28%. Significance. We propose the first data-driven CNN-based inverse MC model to estimate the form of scattering phase function. The effects of field of view and spatial resolution are analyzed and the findings provide guidelines for optimizing the experimental protocol in practical applications.}
}

@article{Liang_2024_VCIBA,
    doi = {10.1186/s42492-024-00153-y},
    url = {https://vciba.springeropen.com/articles/10.1186/s42492-024-00153-y},
    year = {2024},
    month = {February},
    volume = {7},
    number = {4},
    pages = {074001},
    author = {Yuxuan Liang and Chuang Niu and and Pingkun Yan and Ge Wang},
    title = {Flipover outperforms dropout in deep learning},
    journal = {Visual Computing for Industry, Biomedicine, and Art},
    abstract = {Flipover, an enhanced dropout technique, is introduced to improve the robustness of artificial neural networks. In contrast to dropout, which involves randomly removing certain neurons and their connections, flipover randomly selects neurons and reverts their outputs using a negative multiplier during training. This approach offers stronger regularization than conventional dropout, refining model performance by (1) mitigating overfitting, matching or even exceeding the efficacy of dropout; (2) amplifying robustness to noise; and (3) enhancing resilience against adversarial attacks. Extensive experiments across various neural networks affirm the effectiveness of flipover in deep learning.}
}